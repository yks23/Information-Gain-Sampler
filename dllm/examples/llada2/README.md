# LLaDA2.0

> ðŸ“„ Tech report: [Scaling Up Diffusion Language Models to 100B](https://github.com/inclusionAI/LLaDA2.0/blob/main/tech_report.pdf) | ðŸ’» Code: [github.com/inclusionAI/LLaDA2.0](https://github.com/inclusionAI/LLaDA2.0/tree/main)

Resources and examples for sampling **LLaDA2.0**.

## Files
```
# Pipeline modules relevant to LLaDA2
dllm/pipelines/llada2
â”œâ”€â”€ __init__.py                     # Package initialization
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ configuration_llada2_moe.py # LLaDA2-MoE model configuration
â”‚   â””â”€â”€ modeling_llada2_moe.py      # LLaDA2-MoE model architecture
â””â”€â”€ sampler.py                      # Inference module

# Example entry points for inference
examples/llada2
â”œâ”€â”€ chat.py      # Multi-turn chat demo (uses chat template)
â”œâ”€â”€ sample.py    # Single-turn sampling demo
â””â”€â”€ README.md    # Documentation (You are here)
```

## Inference
Set `--model_name_or_path` to your checkpoint (e.g., `inclusionAI/LLaDA2.0-mini`).

We support inference for standard sampling:
```shell
python -u examples/llada2/chat.py --model_name_or_path "inclusionAI/LLaDA2.0-mini"
```

We also support interactive multi-turn dialogue with visualization:
```shell
python -u examples/llada2/sample.py --model_name_or_path "inclusionAI/LLaDA2.0-mini"
```
